Centers for Medicare & Medicaid Services Streamlined Modular Certification Required Monthly Project Status Report Example Structure <Version> Centers for Medicare & Medicaid Services Centers for Medicare & Medicaid Services Centers for Medicare & Medicaid Services - Enter Project Name Streamlined Modular Certification Monthly Project Status Report Enter State Name Version <0.0> 3/23/2022 Notes States are encouraged to use the Streamlined Modular Certification Required Monthly Project Status Report Example Structure during the Design, Development, and Implementation (DDI) phase to appropriately demonstrate project health and how user/stakeholder engagement is collected and used throughout the project. Submission of a monthly project status reports using this structure will satisfy the requirement in the guidance released with SMDL #XX-XXX under Appendix C. The monthly project status reports should be submitted to the states CMS State Officer, and either the MES mailbox (MES@cms.hhs.gov) or CMS Box. States are encouraged to use their ongoing project management repositories, including risk registers and defect trackers, as sources for content in this document to minimize report production effort and ensure consistency between internal (state) and external (CMS) reporting. States may also consider granting their CMS State Officer access to state repositories to more efficiently share information. Monthly project status reports should include the following elements: Introduction A brief overview of the states project Roadmap An up-to-date product roadmap identifying current, planned, and future functionality and milestones Progress Tracking A regular report measuring development progress and progress towards achieving outcomes Risks and Issues Summary of risks and materialized issues that may cause delays and any mitigations or workarounds Defects Summary of key testing activities during the reporting period including changes in status of critical defects. Product Demos Demo of functionality/features, or regular report of code/feature releases Testing Process A documented testing process aligned with the CMS Testing Guidance Framework Revision History Instructions: States should use the table below to record changes made to the report on a monthly basis. No. Date Reference Description of Change Table of Contents 1.0 Introduction 1 2.0 Roadmap 1 3.0 Progress Tracking 1 4.0 Risks and Issues 2 5.0 Defects 2 6.0 Product Demos 2 7.0 Testing Process 3 8.0 Appendix: High-Level Project Schedule 4 1.0 Introduction Instructions: Include a brief executive summary of the states current project accomplishments, challenges, and overview of progress. Please include a reference to the file number for relevant approved Advanced Planning Document(s) (APDs). 2.0 Roadmap Instructions: Provide an up-to-date product roadmap identifying current, planned, and future functionality and identify which major milestones have been accomplished since the last submission. This section should also articulate how the planned product roadmap aligns to an overall state Medicaid Enterprise roadmap and the APD funding, including documenting what has changed since the APD was approved. The roadmap should include dates, or date ranges, for each release or milestone and describe the impact of any changes to the roadmap that occurred during the reporting month. If milestones or release dates have been moved, the state should include the reason in this section. 3.0 Progress Tracking Instructions: Provide a project schedule that shows how the state development, business teams, and vendor will measure the timeliness of development efforts. The project schedule should include planned go-live and a potential Operational Readiness Review (ORR) date (if an ORR date has been discussed with CMS) If there are project delays, please provide a specific description of schedule delays that may affect the overall go-live date (refer to sections 4.0 Risks and Issues and 5.0 Defects for additional detail). States should highlight any incremental progress against program, policy, and/or outcomes and include information on how the state is preparing for implementation (e.g., planned and conducted trainings, organizational change management activities, engagements with stakeholders, etc.) to support the successful delivery of the project and ongoing operations. The state should also identify major activities and events scheduled for the next two reporting periods. 4.0 Risks and Issues Instructions: Describe changes to overall project risk profile during the monthly reporting period. Please include an assessment of implementation risks such as Go/No-Go exit criteria before production release(s). States should provide a list of active high priority risks and issues that could have an adverse (e.g., scope, cost, schedule) impact on the project and describe any mitigations or workarounds. These risks and issues should include operational impact and a summarized mitigation/resolution plan or a risk acceptance statement that includes user/stakeholder input and consensus. 5.0 Defects Instructions: Provide a list of active critical and/or high severity defects and related mitigations or workarounds. Defect entries should include information about the operational impact and timeline for resolution. 6.0 Product Demos Instructions: States should communicate the schedule for product demonstrations so that their CMS State Officer has the opportunity to attend any demonstrations or testing events that would be beneficial to understanding project progress and preparation for the ORR. 7.0 Testing Process Instructions: Provide an overview of the documented testing process aligned with and informed by the CMS Testing Guidance Framework which offers specific MES testing expectations and recommendations. States should demonstrate progress against the states master test plan and any changes or updates to the master test plan should be specifically noted. In particular, states should identify user/stakeholder engagement completed during the testing process and confirm they have included actual users in both user acceptance and usability testing. Discussion of test results, including security test results, should not only validate the iterative delivery of system functionality, but also confirm that the system will produce metrics associated with outcomes approved in their APD. States should indicate whether performance and security testing was as automated as possible (e.g., continuous unit testing) and map functionality to outcome achievement. 4 Enter State Name Enter Project Name Streamlined Modular Certification Required Monthly Project Status Report ii 3 4 3